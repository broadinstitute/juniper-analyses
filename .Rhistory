remove.packages("juniper0")
devtools::install_github("broadinstitute/juniper0")
library(juniper0)
### Validation of JUNIPER's ability to reconstruct epidemics
library(juniper0)
library(simulatR)
library(ape)
library(reshape2)
library(outbreaker2)
args <- as.numeric(commandArgs(TRUE))
#print(args)
# Default params
defaults <- list(
mu_g = 5,
var_g = 5,
mu_s = 5,
var_s = 5,
mu = 2e-5,
N_eff = log(100),
p_sample = 0.5,
trans_sample = NA,
R = 2,
psi = 0.5,
coverage = 1
)
params <- names(defaults)
# Alternative params
alternatives <- list(
mu_g = c(2.5, 10),
var_g = c(2.5, 10),
mu_s = c(2.5, 10),
var_s = c(2.5, 10),
mu = c(1e-5, 4e-5),
N_eff = c(log(20), log(500)),
p_sample = c(0.25, 0.75),
trans_sample = c(0.25, 0.75),
R = c(1.5, 2.5),
psi = c(0.25, 0.75),
coverage = c(0.8, 0.9)
)
# Matrix of parameter inputs per experiment
combos <- as.data.frame(defaults)
for (p in params) {
for (j in 1:length(alternatives[[p]])) {
newrow <- combos[1, ]
newrow[[p]] <- alternatives[[p]][j]
combos <- rbind(combos, newrow)
}
}
# Create a new directory, if needed, for experiment i
dname <- paste0("experiment_", i)
set.seed(1)
init <- initialize(
n_subtrees = 1, # We will parallelize over simulations, not within each one
n_global = n_global,
indir = paste0(dname, "/input_data"),
a_g = combos$mu_g[i]^2 / combos$var_g[i],
lambda_g = combos$mu_g[i] / combos$var_g[i],
a_s = combos$mu_s[i]^2 / combos$var_s[i],
lambda_s = combos$mu_s[i] / combos$var_s[i],
psi = combos$psi[i],
init_mu = combos$mu[i],
init_N_eff = combos$N_eff[i]
)
i=1
# Create a new directory, if needed, for experiment i
dname <- paste0("experiment_", i)
set.seed(1)
init <- initialize(
n_subtrees = 1, # We will parallelize over simulations, not within each one
n_global = n_global,
indir = paste0(dname, "/input_data"),
a_g = combos$mu_g[i]^2 / combos$var_g[i],
lambda_g = combos$mu_g[i] / combos$var_g[i],
a_s = combos$mu_s[i]^2 / combos$var_s[i],
lambda_s = combos$mu_s[i] / combos$var_s[i],
psi = combos$psi[i],
init_mu = combos$mu[i],
init_N_eff = combos$N_eff[i]
)
i
# For reproducible results that vary by experiment
set.seed(i)
# Simulate epidemic by rejection sampling
done <- F
while(!done){
done <- epi_sim(
a_g = combos$mu_g[i]^2 / combos$var_g[i],
lambda_g = combos$mu_g[i] / combos$var_g[i],
a_s = combos$mu_s[i]^2 / combos$var_s[i],
lambda_s = combos$mu_s[i] / combos$var_s[i],
R = combos$R[i],
psi = combos$psi[i],
mu = combos$mu[i],
N_eff = combos$N_eff[i],
init_genome = rep("A", 10000), # Initialize to genome of all A's
p_samp = combos$p_sample[i],
trans_samp = combos$trans_sample[i],
coverage = combos$coverage[i],
n_obs = 50,
include_root = F,
outdir = paste0("./", dname, "/input_data")
)
}
## Write metadata
fasta <- ape::read.FASTA(paste0("./", dname, "/input_data/aligned.fasta"))
fasta
samples <- gsub(".*\\|", "", names(fasta))
samples
dates <- gsub(".*\\|", "", names(fasta))
samples <- gsub("\\|.*", "", names(fasta))
samples
meta <- data.frame(sample = samples, date = dates)
meta
write.csv(meta, file = paste0("./", dname, "/input_data/metadata.csv"), row.names = F, quote = F)
# Reconstruct, first with perfectly-specified inputs
set.seed(1)
init <- initialize(
n_subtrees = 1, # We will parallelize over simulations, not within each one
n_global = n_global,
indir = paste0(dname, "/input_data"),
a_g = combos$mu_g[i]^2 / combos$var_g[i],
lambda_g = combos$mu_g[i] / combos$var_g[i],
a_s = combos$mu_s[i]^2 / combos$var_s[i],
lambda_s = combos$mu_s[i] / combos$var_s[i],
psi = combos$psi[i],
init_mu = combos$mu[i],
init_N_eff = combos$N_eff[i]
)
n_global = 100
init <- initialize(
n_subtrees = 1, # We will parallelize over simulations, not within each one
n_global = n_global,
indir = paste0(dname, "/input_data"),
a_g = combos$mu_g[i]^2 / combos$var_g[i],
lambda_g = combos$mu_g[i] / combos$var_g[i],
a_s = combos$mu_s[i]^2 / combos$var_s[i],
lambda_s = combos$mu_s[i] / combos$var_s[i],
psi = combos$psi[i],
init_mu = combos$mu[i],
init_N_eff = combos$N_eff[i]
)
res <- run_mcmc(init)
res <- run_mcmc(init, T, T)
